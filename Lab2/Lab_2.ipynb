{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CS 3315 Lab 2\n",
    "Snyder\n",
    "Finley"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   # CS3315 Introduction to Machine Learning and Big Data\n",
    "\n",
    "   ### Prof. Barton\n",
    "\n",
    "   # Lab 1\n",
    "\n",
    "### Default of Credit Card Clients.\n",
    "\n",
    "The data set \"credit_card_default.csv\" consists of several features that describe customer's credit information. The last column called \"default payment next month\" is a binary label indicating if a customer will default (Yes = 1, No = 0) on their credit card payment. The features may be used to predict if a customer will default or not default next month. Below is a description of the features:\n",
    "\n",
    "X1: Amount of the given credit (NT dollar): it includes both the individual consumer credit and his/her family (supplementary) credit.\n",
    "\n",
    "X2: Gender (MALE; FEMALE).\n",
    "\n",
    "X3: Education (GRADUATE SCHOOL; UNIVERSITY; HIGH SCHOOL; OTHER).\n",
    "\n",
    "X4: Marital status (1 = married; 2 = single; 3 = others).\n",
    "\n",
    "X5: Age (year).\n",
    "\n",
    "X6 - X11: History of past payment. We tracked the past monthly payment records (from April to September, 2005) as follows: X6 = the repayment status in September, 2005; X7 = the repayment status in August, 2005; . . .;X11 = the repayment status in April, 2005. The measurement scale for the repayment status is: -1 = pay duly; 1 = payment delay for one month; 2 = payment delay for two months; . . .; 8 = payment delay for eight months; 9 = payment delay for nine months and above.\n",
    "\n",
    "X12-X17: Amount of bill statement (NT dollar). X12 = amount of bill statement in September, 2005; X13 = amount of bill statement in August, 2005; . . .; X17 = amount of bill statement in April, 2005.\n",
    "\n",
    "X18-X23: Amount of previous payment (NT dollar). X18 = amount paid in September, 2005; X19 = amount paid in August, 2005; . . .;X23 = amount paid in April, 2005.\n",
    "\n",
    "\n",
    "### Please complete the exercises below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "a. Load the data set 'credit_card_default.csv' into a Pandas DataFrame. Execute the following functions on the DataFrame and print the results: 1) head(), 2) info(), 3) describe(), 4) isnull().sum(). \n",
    "\n",
    "b. Set the 'ID' column to be the new row index using the set_index() function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the data from the csv file\n",
    "df = pd.read_csv('credit_card_default.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the ID row to be the index\n",
    "df = df.set_index('ID')\n",
    "\n",
    "#verify\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "a. Plot a histogram matrix using the hist() function. In your own words, please describe some insights about the data that you notice form the histograms.\n",
    "\n",
    "b. Print the correlation coefficients using the corr() funtion. Which features have a positive correlation? In your own words, please describe why those featuers may have a positive correlation.\n",
    "\n",
    "c. Plot a scatter matrix using the following attributes: \"PAY_0\", \"PAY_2\", \"PAY_3\", \"LIMIT_BAL\",\"default payment next month\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a histogram of the data\n",
    "df.hist(figsize=(15,15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the above histogram there seems to be not a huge spread of information in the data. Much of the data is Zero on many of the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the above corralation table there seems to be large corralation between pay and bills. This makes sense because we are using pay information. Expenses would corralate to pay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c. Plot a scatter matrix using the following attributes: \"PAY_0\", \"PAY_2\", \"PAY_3\", \"LIMIT_BAL\",\"default payment next month\".\n",
    "plot_df = df.loc[:,['PAY_0', 'PAY_2', 'PAY_3', 'LIMIT_BAL','default payment next month']]\n",
    "pd.plotting.scatter_matrix(plot_df, figsize=(15,15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "\n",
    "a. The 'SEX' column contans values 'MALE' and 'FEMALE'. Write a custom ordinal encoder function that encodes 'MALE' to 0 and 'FEMALE' to 1. Apply the function to the 'SEX' column.\n",
    "\n",
    "b. The 'EDUCATION' column contains values 'GRADUATE SCHOOL', 'UNIVERSITY', 'HIGH SCHOOL', and 'OTHER'. Write a one hot encoder function and apply it to the 'EDUCATION' column. After this you should have four new binary columns, one for each category.\n",
    "\n",
    "c. Drop the previous 'EDUCATION' column from the DataFrame. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code is similar to whar we learned in class and pg.66 of the HOML textbook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make the encoder\n",
    "def ordinal_encoder(cat):\n",
    "    dict = {'MALE':0, 'FEMALE':1}\n",
    "    return dict[cat]\n",
    "\n",
    "#verify\n",
    "#print(\"MALE\", ordinal_encoder('MALE'))\n",
    "#print(\"FEMALE\", ordinal_encoder('FEMALE'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SEX']= df['SEX'].apply(ordinal_encoder)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the one hot encoding for the education catagory\n",
    "\n",
    "\n",
    "b. The 'EDUCATION' column contains values 'GRADUATE SCHOOL', 'UNIVERSITY', 'HIGH SCHOOL', and 'OTHER'. Write a one hot encoder function and apply it to the 'EDUCATION' column. After this you should have four new binary columns, one for each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneHot(cat,hot):\n",
    "    if cat == hot:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do one hot for \"GRADUATE SCHOOL\", \"UNIVERSITY\", \"HIGH SCHOOL\", \"OTHER\"\n",
    "df['GRADUATE SCHOOL'] = df['EDUCATION'].apply(oneHot, hot='GRADUATE SCHOOL')\n",
    "df['UNIVERSITY'] = df['EDUCATION'].apply(oneHot, hot='UNIVERSITY')\n",
    "df['HIGH SCHOOL'] = df['EDUCATION'].apply(oneHot, hot='HIGH SCHOOL')\n",
    "df['OTHER'] = df['EDUCATION'].apply(oneHot, hot='OTHER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verift\n",
    "df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c. Drop the previous 'EDUCATION' column from the DataFrame\n",
    "df = df.drop(['EDUCATION'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Please run the code block below to split the data into X (feature vectors), and y (labels).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['default payment next month'],axis=1)\n",
    "y = df[['default payment next month']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please run the code block below to apply feature scaling to the feature vectors X.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('std_scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "df_scaled = pipeline.fit_transform(X)\n",
    "X = pd.DataFrame(df_scaled)\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please Run the code blocks below** to split the data into train and test sets, and to train the classifier.  Note, the following code expects **feature vectors X** and **labels y** as arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "sgd_clf = KNeighborsClassifier(n_neighbors=11)\n",
    "sgd_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = sgd_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5\n",
    "\n",
    "a. Calculate accuracy.\n",
    "\n",
    "b. Calculate precision.\n",
    "\n",
    "c. Calculate recall.\n",
    "\n",
    "d. Calculate F1 score.\n",
    "\n",
    "e. Which error is higher in the model, false positives or false negatives? If a credit card company uses this classifer to decide whether or not to approve customers, which error may be more costly to the credit card company and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the accuracy of the model\n",
    "#ref  pg.89 of Hands on Machine Learning with Scikit-Learn and TensorFlow\n",
    "n_correct = 0\n",
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i] == y_test['default payment next month'].iloc[i]:\n",
    "        n_correct += 1\n",
    "print(n_correct)\n",
    "print(\"The accuracy of the model is: \", n_correct/len(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#many of these things are held in a confusion matrix\n",
    "#page 90 in Hands on Machine Learning with Scikit-Learn and TensorFlow\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#print what is in a confusion matrix\n",
    "print(\"The confusion matrix is: \\nTrue positive\\t|False Negative\\nFalse Positive\\t|True Negative\")\n",
    "cm = confusion_matrix(y_true=y_test,y_pred= y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_true = y_test, y_pred= y_pred).ravel()\n",
    "print(\"True Negative: \", tn)\n",
    "print(\"False Positive: \", fp)\n",
    "print(\"False Negative: \", fn)\n",
    "print(\"True Positive: \", tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TN = cm[0][0]\n",
    "FN = cm[1][0]\n",
    "FP = cm[0][1]\n",
    "TP = cm[1][1]\n",
    "\n",
    "print(\"{}|{}\\n{}|{}\".format(TP,FP,FN,TN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (TP+TN) / (TP+FN+FP+TN)\n",
    "precision = TP / (TP+FP)\n",
    "recall = TP / (TP+FN)\n",
    "\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"precision: \", precision)\n",
    "print(\"Recall: \", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate F1 Score for the model\n",
    "F1 = (2 * (precision * recall)) / (precision + recall)\n",
    "print(\"F1 Score: \", F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Precision and recall with skler functrions for verification\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "p = precision_score(y_test, y_pred)\n",
    "r = recall_score(y_test, y_pred)\n",
    "print(\"Precision: \", p)\n",
    "print(\"Recall: \", r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"False Positives\\t \", FP)\n",
    "print(\"False Negatives\\t \", FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "False Positives were higher. The \"costlier\" of the two would be false negatives. If a fradulent purchase is made that would be considered lost money. This would be more inconvenient for the custumer becuase more legitamate transactions would be stopped."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "80079d8dd9f7c252f0ff3be33272006cb63eba2cb77317ddc2afd11fdc1d0064"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
